{"meta":{"title":"Red Peregrine","subtitle":"Carl Scarlett's Blog","description":"Red Peregrine is the blog site of Carl Scarlett","author":"Carl Scarlett","url":"http://www.redperegrine.net"},"pages":[{"title":"About","date":"2018-04-01T03:05:57.000Z","updated":"2018-05-09T08:26:03.582Z","comments":true,"path":"about/index.html","permalink":"http://www.redperegrine.net/about/index.html","excerpt":"","text":"About Me![A picture of me; Carl Scarlett][avatar-picture.png] My name is Carl Scarlett. I’ve been a professional software developer since 1995. In More DetailMy name is Carl Scarlett. I grew up with the home computer revolution, and since my first computer at about 8 years of age I’ve been fascinated by software and software development. As I progressed through my secondary school years I was exposed to the business side of computers as well as simulations and gaming. When it came time to choose a tertiary educational path I followed my passion and completed a double-major in Computer Science and Information Technology. Since graduation I’ve worked solely in the every-expanding IT industry, filling a variety of roles but always relating to the development of software solutions. My passion for software has deep roots in the early gaming industry where a lone wolf would create an entire product end to end including game and UI design, coding, music, and graphics. Throughout my career I’ve always sought out roles to help me learn everything and everything so that I had all the skills required to develop products on my own, which has made me a valuable team member as I can spot and fill any skill gap to keep the team moving forward. I’ve also had a successful sporting career (Australian rules football and predominantly cricket), where I learned the value of team work and developed my leadership style combining mentoring with showing by doing. While I’m able to work independently, I prefer being part of motivated teams where I can bring my experience to ensuring the team is operating at it’s best efficiency and always focusing on problems the right way. About this SiteThis website is built using [Hexo][hexo], a static website generator built with [Node.js][node]. I use the [Icarus][icarus] theme, which I’ve modified to suit my needs. Text content is created using [Markdown][markdown]. I use [VS Code][vscode] for text editing and task running (such as site generation), and a personally licensed version of [Affinity Designer][afdesign] for image editing. [hexo]:[node]:[markdown]:[icarus]:[vscode]:[afdesign]:"},{"title":"Categories","date":"2017-12-16T06:44:09.363Z","updated":"2017-12-16T06:44:09.363Z","comments":true,"path":"categories/index.html","permalink":"http://www.redperegrine.net/categories/index.html","excerpt":"","text":""},{"title":"Tags","date":"2017-12-16T06:44:14.003Z","updated":"2017-12-16T06:44:14.003Z","comments":true,"path":"tags/index.html","permalink":"http://www.redperegrine.net/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Building a Pause Menu - Part 1","slug":"building-a-pause-menu-part-1","date":"2018-12-30T09:34:58.000Z","updated":"2019-05-01T09:06:47.215Z","comments":true,"path":"2018/12/30/building-a-pause-menu-part-1/","link":"","permalink":"http://www.redperegrine.net/2018/12/30/building-a-pause-menu-part-1/","excerpt":"I built a pause menu to improve the experience on my Android phone.","text":"I built a pause menu to improve the experience on my Android phone. BackgroundAfter constructing a home menu for my Capability Test App (see my last post) I thought I was done with menus for a while. However the experience of closing and re-opening the app just to change tests quickly became tedious. I wanted to address this pain before adding more. The time was right to build a Pause Menu providing in-app navigation. This also allowed me to explore how Godot handles game pausing (a feature I’ll use in the future). It was an opportunity to kill two birds with one stone. The Godot Pause MechanismThe Godot engine has a simple mechanism for pausing a game. Flipping the get_tree().paused boolean to true at run-time sends your game into pause mode. In pause mode your input handlers and process loop code are no longer called by default, stopping your game from running. Then you configure the nodes you want to continue processing during pause mode. In my case this meant configuring a Pause Menu scene that contains controls to unpause the game, go back home (i.e. to the Main Menu), and to quit the app. You can add whatever features you want to run while the game is paused. It’s a very simple and effective system. Evolving the Solution ArchitectureIt may be easy to build a Pause Menu UI and hook up to Godot’s pause mechanism, but to perform the navigation back to the Main Menu I needed to evolve my architecture. Previously the only navigation in the app was launching a new scene when selected from the Main Menu. At the time it was appropriate for the Main Scene script to handle instancing and launching of the selected test scene. With the introduction of a Pause Menu, navigation back to the Main Menu was now required. This meant rethinking how scene creation, activation, and navigation was handled throughout the app. To prevent the navigation code spreading throughout the codebase as the app grew, I decided to replace existing navigation code with a centralised service. After considering various ways to achieve this I created a gameStateManager node to be this service. This node would be responsible for scene navigation via a SetActiveScene() function. It would also track the state of the app (GamePaused or PlayingScene) and expose a command system to allow navigation to the various fixed game scenes and states (PauseGame, GoHome, QuitApp, ContinueGame). Naming ConventionsMy personal preference is to use the term “Manager” instead of “Controller” when I name such objects. When I talk about “Manager” objects it’s likely your own understanding of a “Service” or an MVC “Controller” object accurately describes my intention here. After a first pass at writing the gameStateManager I found my code was too messy. I took this code smell to indicate my gameStateManager was doing too much and needed breaking apart. I created two child nodes; an activeSceneManager responsible for changing the active scene, and a pauseSceneManager responsible for managing the Pause Menu and its operations. The gameStateManager remained the central point for processing game commands and tracking the game state. This breakdown keeps each node focused on a single area of responsibility (the ‘S’ in SOLID design principles). noteAt this point in learning Godot I’m finding it difficult to apply object-oriented design principles (such as SOLID) to the node system. Nodes seem to behave more like methods on an object than as objects themselves, which feels a little unnatural. However my instincts about when to break script files apart still trigger in a timely fashion. I’m getting more of a feel for how and when to listen to my instincts while working in Godot, and I’m building my personal development rhythm for organically growing a GDScript codebase. Using Signals as a Messaging SystemThere are two types of messages my navigation system needs to work. First I have game scenes that need to change the active scene by messaging the activeSceneManager. Second I have a Pause Menu that needs to send game commands to the gameStateManager for processing. All my game scenes (the Main Menu, Pause Menu, and capability test scenes) are created by the Manager nodes. This provides an opportunity to connect signals from game scenes to the Manager nodes at the point of creation. As long as these signals implement standard message contracts, a one-way message channel is formed from the game scene to the appropriate Manager node along which messages can be passed. The ‘SetActiveScene’ Message Channel (and Contract)If a game scene (such as my Main Menu) has a requirement to navigate to a new scene, it must implement a signal I’ve called SetActiveScene(args) . The contract for args is a dictionary containing a key of either sceneInstance or scenePath, and an optional key sceneName. An existing node instance or path must be passed as the value. The sceneName value is only used for debug output. The signal is connected to the SetActiveScene(args) function in the activeSceneManager. When a node instance or path is passed in the args, the activeSceneManager creates the new scene instance (or use the passed one), sets the new scene instance as the active one, and connects the SetActiveScene(args) signal of this new instance to itself. The new node is added as a child of the activeSceneManager itself. The previously active scene child node is removed (if there is one) and signal connections are disconnected. Thus when the currently active scene needs to navigate to a new scene, it calls emit_signal on SetActiveScene with appropriately message args and the navigation is performed by the activeSceneManager. 12345678910111213141516171819202122232425262728var _activeSceneInstance[...]func SetActiveScene(args): var nodeInstance if (args.has(\"sceneInstance\")): nodeInstance = args.sceneInstance elif (args.has(\"scenePath\")): nodeInstance = load(args.scenePath).instance() else: return if (args.has(\"sceneName\")): print([\"Playing Scene\", args.sceneName]) RemoveActiveScene() _activeSceneInstance = nodeInstance _activeSceneInstance.connect(\"SetActiveScene\", self, \"SetActiveScene\") self.add_child(nodeInstance)func RemoveActiveScene(): if (_activeSceneInstance == null): return _activeSceneInstance.disconnect(\"SetActiveScene\", self, \"SetActiveScene\") remove_child(_activeSceneInstance) _activeSceneInstance = null Managing the active scene and connecting the SetActiveScene signal in the activeSceneManager The ‘ExecuteGameCommand’ Message Channel (and Contract)The game command message channel is implemented differently. Currently in my Capability Test app the only node required to send game commands is the Pause Menu scene. Because the Pause Menu’s UI maps directly to game commands I can hardwire signal connections from the Pause Menu scene directly to the gameStateManager when it is created by the pauseSceneManager. To do this I created MenuSelected(), QuitSelected() and PlaySelected() signals on the Pause Menu scene. These are emitted by the Pause Menu scene when the user selects the Menu, Quit or Play buttons on the Pause Menu. These signals are connected to an ExecuteGameCommand(command) function on the gameStateManager by the pauseSceneManager as the game boots. In this case the message (the command parameter) is a simple enum value. 1enum gameCommand &#123; PauseGame, GoHome, QuitApp, ContinueGame &#125; When the pauseSceneManager creates the Pause Menu it connects its signals using a hardcoded message value. 1234567var _pauseSceneInstancefunc Initialise(gameStateManager, pauseScenePath): _pauseSceneInstance = load(pauseScenePath).instance() _pauseSceneInstance.connect(\"MenuSelected\", gameStateManager, \"ExecuteGameCommand\", [ gameCommand.GoHome ]) _pauseSceneInstance.connect(\"QuitSelected\", gameStateManager, \"ExecuteGameCommand\", [ gameCommand.QuitApp ]) _pauseSceneInstance.connect(\"PlaySelected\", gameStateManager, \"ExecuteGameCommand\", [ gameCommand.ContinueGame ]) Creating the game command message channel from pause menu to the gameStateManager The ExecuteGameCommand(command) function on the gameStateManager simply checks which command was passed and performs the desired actions. It either updates the game state and shows/hides its manager node children, or quits the app. 12345678910111213141516171819202122func ExecuteGameCommand(command): match command: gameCommand.GoHome: SetGameState(gameState.PlayingScene) $activeSceneManager.Home(); $pauseSceneManager.Hide() gameCommand.PauseGame: SetGameState(gameState.GamePaused) $pauseSceneManager.Show() gameCommand.ContinueGame: SetGameState(gameState.PlayingScene) $pauseSceneManager.Hide() gameCommand.QuitApp: get_tree().quit()func SetGameState(state): match state: gameState.GamePaused: get_tree().paused = true gameState.PlayingScene: get_tree().paused = false _currentGameState = state The gameStateManager being responsible for changing state and executing game commands The BootstrapWhen the app first starts I need to do some preparation before the app is ready to be consumed by the user. The environment in which the app runs needs to be configured, and the initial game scenes and nodes required need to be created and instanced. When this preparation is done using code it is called a Bootstrap, and is an example of the Bootstrapping design pattern. The code entry point of my app is the _ready() function in the the game scene script. This is where my bootstrap begins. Its first task is to configure the run-time environment for the app, which is performed using Godot engine properties and commands: The mouse pointer is hidden. My app is controlled purely with touch (even on Windows desktop) I configure Godot not to quit automatically. I will manage when the app closes using a Main Menu. I configure Godot not to quit when Back is pressed. This setting is used when the game is running on Android. noteA consequence of configuring quit behaviour is the app must handle OS events. I’ll talk about that later in this post. 1234# Set up game environmentInput.set_mouse_mode(Input.MOUSE_MODE_HIDDEN)get_tree().set_auto_accept_quit(false) # Must be false to allow pause menu to work on Androidget_tree().set_quit_on_go_back(false) # Must be false to allow pause menu to work on Android The second task is to initialise the game scenes and nodes. Rather than hardcoding or hardwiring scenes with the editor, all my game scenes (the Main Menu, Pause Menu, and capability test scenes) are defined using data. When the app first starts I want the Main Menu to show and have the Pause Menu ready. I pass the paths of these scenes to the gameStateManager for creating, instancing, and adding to the game scene’s tree using a custom function called Initialise. 1$gameStateManager.Initialise(\"res://game/menu/Main.tscn\", \"res://pauseMenu/PauseMenu.tscn\") The gameStateManager initialises its child Manager nodes activeSceneManager and pauseSceneManager by passing relevant scene paths using more custom Initialise functions. Once those complete the initial game state is set to gamestate.PlayingScene. 1234func Initialise(homeScenePath, pauseScenePath): $activeSceneManager.Initialise(homeScenePath) $pauseSceneManager.Initialise(pauseScenePath) SetGameState(gameState.PlayingScene) Initialise on activeSceneManager creates an instance of the Main Menu using the passed homeScenePath. It keeps a reference to this instance for later (navigation back to the Main Menu), and sets it as the active scene. This adds the Main Menu instance as a child of activeSceneManager (itself). Because activeSceneManager manages the app’s active scene, this is achieved using only local function calls (SetActiveScene() via Home()). 12345678910var _homeSceneInstance;func Initialise(homeScenePath): _homeSceneInstance = load(homeScenePath).instance() Home()[...]func Home(): SetActiveScene(&#123; sceneInstance = _homeSceneInstance, sceneName = \"Home\"&#125;) Initialise on pauseSceneManager creates an instance of the Pause Menu using the passed pauseScenePath. It creates an instance of the Pause Menu, wires up the ExecuteGameCommand message signals to the gameStateManager, hides the instance, and adds it as a child of pauseSceneManager (itself). 123456789101112func Initialise(pauseScenePath): var gameStateManager = self.get_parent() _pauseSceneInstance = load(pauseScenePath).instance() _pauseSceneInstance.connect(\"MenuSelected\", gameStateManager, \"ExecuteGameCommand\", [ gameCommand.GoHome ]) _pauseSceneInstance.connect(\"QuitSelected\", gameStateManager, \"ExecuteGameCommand\", [ gameCommand.QuitApp ]) _pauseSceneInstance.connect(\"PlaySelected\", gameStateManager, \"ExecuteGameCommand\", [ gameCommand.ContinueGame ]) _pauseSceneInstance.hide() self.add_child(_pauseSceneInstance)func Hide(): _pauseSceneInstance.hide() noteBecause pauseSceneManager is a sibling lower in the game scene tree than activeSceneManager, the Pause Menu will appear on top of the active scene. The background of the Pause Menu is partially transparent to allow the active scene to be visible underneath when the Pause Menu is shown. Godot System NotificationsI configured Godot to ignore quit requests because I want to manage how the app closes myself. I want the Pause Menu to appear when the app window loses focus on desktop environments or the back button is pressed on Android. This is achieved by handling system notifications emitted by Godot. Godot’s notification system uses event-like function calls to notify different parts of the engine when system events occur. Godot games and apps can also choose to be notified and respond to these events by implementing a _notification(what) function in any script(s). Each notification has a unique ID to identify what event occurred, and each ID is exposed as a constant in the MainLoop class to facilitate responding appropriately. In my case I want the gameStateManager to show the Pause Menu when the app window loses focus (MainLoop.NOTIFICATION_WM_FOCUS_OUT) or the back button is pressed (MainLoop.NOTIFICATION_WM_GO_BACK_REQUEST). I also want the app to terminate when the app desktop window is closed or the Quit option is selected on the Pause Menu (MainLoop.NOTIFICATION_WM_QUIT_REQUEST). By implementing a _notification() function in the gameStateManager script I can use local function calls to ExecuteGameCommand() and pass the relevant gameCommand value to achieve the desired effect. 12345678func _notification(what): match (what): MainLoop.NOTIFICATION_WM_FOCUS_OUT: ExecuteGameCommand(gameCommand.PauseGame) MainLoop.NOTIFICATION_WM_QUIT_REQUEST: ExecuteGameCommand(gameCommand.QuitApp) MainLoop.NOTIFICATION_WM_GO_BACK_REQUEST: ExecuteGameCommand(gameCommand.PauseGame) Now the game reacts appropriately to operating system events, shows the Pause Menu and terminates when I want it to… except… Godot Games Cannot Terminate Themselves on AndroidOn Android systems a call to get_tree().quit() doesn’t terminate the app. Android appears to be designed this way, as if all applications running on it are services that should always remain open. Currently it requires the user to force the application closed by using Android’s overview (square) button. There seems to be valid ways to force close Android apps in Java, so I have created a feature request to allow Godot to support force closing in the future. Moving Navigation from the Main Menu ScriptWith the Pause Menu hooked up all that remains is to remove the old navigation code used by the Main Menu to launch the various test scenes and replace them with the SetActiveScene message channel. As previously described this is a simple matter of implementing the SetActiveScene(args) signal in the Main Menu script and emitting it with correctly populated message arguments. The connection of the signal is done for the Main Menu scene during its creation by the activeSceneManager. Within the Main Menu scene the buttons are connected to a single OnButtonPressed function in the script. When a button is pressed it passes the details of the test scene selected. Where OnButtonPressed used to create and instance the test scene when called, it now simply emits the SetActiveScene signal and constructs a message using the details passed in. The activeSceneManager does the heavy lifting and looks after the game state. 12func OnButtonPressed(scenePath, sceneName): emit_signal(\"SetActiveScene\", &#123; scenePath = scenePath, sceneName = sceneName &#125;) Ready to RollNow everything is in place and we are ready to run the application. Here’s a video of the application running on Windows (a desktop scenario): The Pause Menu on Windows Desktop Here’s a video of the game running on Android phone. The Pause Menu on Android Phone Designing to Improve the Android ExperienceHere’s a video showing the issue where Android doesn’t quit to highlight why it’s an issue. Godot 3 can’t quit on Android! Given I can’t force the app to close on Android at the moment, the only option I have is to employ clever design choices to counteract this woeful experience. I’ve reflected on this issue for some time. The best options I’ve come up with so far are to either change the button label from Quit to Close (or Minimise), and/or add another label to the Pause Menu explaining that you have to manually close down the app. I would only want these changes to appear when running on Android to avoid breaking the current design for other platforms. Further research is needed to discover how to achieve this, though I suspect adding an argument when exporting to Android will be the first thing to investigate. In any case I’m not happy with either of these options from an aesthetic point of view. I like the symmetry of the current design with short four-letter words to describe intent. I also like the current icons that accurately describe what the intention of the button is by mimicking real-world hardware devices. Changing these to accommodate a functional shortfall on Android weakens the current design to the point at which I’m forced to consider a complete redesign for the Pause Menu. I’m deferring that line of thinking for another time. The best outcome for me is that Godot will support force closing on Android in the future. Given I’m not writing a releasable game just yet (I’m still testing Godot’s capabilities) I can afford to wait to see what happens. Right now I have a menu that works for my current use case and I’ve implemented a nice navigation system that will stand up to future expansion of my app. The code from this article is up on Github as a Gist. I’ll be back in the new year with more posts about my adventures in Godot development. See you then!","categories":[{"name":"gamedev","slug":"gamedev","permalink":"http://www.redperegrine.net/categories/gamedev/"},{"name":"indiedev","slug":"gamedev/indiedev","permalink":"http://www.redperegrine.net/categories/gamedev/indiedev/"},{"name":"godot","slug":"godot","permalink":"http://www.redperegrine.net/categories/godot/"},{"name":"gdscript","slug":"godot/gdscript","permalink":"http://www.redperegrine.net/categories/godot/gdscript/"},{"name":"zodproj","slug":"zodproj","permalink":"http://www.redperegrine.net/categories/zodproj/"},{"name":"game","slug":"zodproj/game","permalink":"http://www.redperegrine.net/categories/zodproj/game/"}],"tags":[{"name":"GUI","slug":"GUI","permalink":"http://www.redperegrine.net/tags/GUI/"},{"name":"Menu","slug":"Menu","permalink":"http://www.redperegrine.net/tags/Menu/"},{"name":"Godot","slug":"Godot","permalink":"http://www.redperegrine.net/tags/Godot/"},{"name":"GDScript","slug":"GDScript","permalink":"http://www.redperegrine.net/tags/GDScript/"}]},{"title":"Preventing Visual Studio Recompiles in UWP","slug":"prevent-vs-recompile-uwp","date":"2018-11-10T03:58:42.000Z","updated":"2018-11-10T08:09:19.998Z","comments":true,"path":"2018/11/10/prevent-vs-recompile-uwp/","link":"","permalink":"http://www.redperegrine.net/2018/11/10/prevent-vs-recompile-uwp/","excerpt":"I’ve discovered a circumstance where Visual Studio compiles UWP projects every time.","text":"I’ve discovered a circumstance where Visual Studio compiles UWP projects every time.noteThis is a reworked internal blog I posted at my current employer. I’ve altered entity names to avoid IP issues. The ProblemIn my development team we were being slowed down by unneccessary Visual Studio recompiles of UWP projects. We have several projects in our solution structure with quite a few dependencies between them, so it’s reasonable to expect compiles could take a while if you’re changing things upstream in the dependency chain. However when nothing was being changed, we were finding certain UWP projects were still being recompiled by Visual Studio. Those recompiles were taking significant time (over a minute on my Surface Pro 5), which was disrupting our developer flow and sapping our productivity. Sometimes you just need to iterate fast through a few debugging sessions to get a task done, and “edit and continue” isn’t possible in all those scenarios. ResearchThe first place developers look to solve problems like “Visual Studio builds when nothing has changed” is Google. There’s a lot of developers in the world, and it’s likely someone has seen and solved this type of problem before. A few hits were returned when I searched, but nothing to solve our particular flavour of this issue. One hit did provide a means of diagnosis and potentially solving the problem myself, so I started following that. Kudos to this external article: Why Visual Studio keeps rebuilding my projects for no good reason AnalysisThe key takeaway from the article is to turn the build output verbosity up to diagnostic levels and examine the output. When you do this, the output window is flooded with information from MSBuild showing exactly what it’s doing during a build. By examining such output you get a real sense of how much complexity is managed by modern compilers on our behalf, and you gain an appreciation of how much it’s doing for you. The key clue to what’s causing the problem is in the first few lines of the output of each project build. In my case it was the following line: 1Project &apos;In-house.Framework&apos; is not up to date. Copy to output file &apos;C:\\dev\\SolutionFolder\\ProjectFolder\\Source\\In-house.Framework\\bin\\x64\\Debug\\Themes\\Generic.xaml&apos; missing from output location. The build expected a xaml file to be present and it wasn’t. If I did 2 builds consecutively this line persisted, so clearly Visual Studio needed some help to get this file output. The reflex for any seasoned developer seeing this message is to find the source file and set its Copy to Output Directory property value to Copy if newer. This means that if there is no file in the bin folder already, or the file is present but is an older version at build time, Visual Studio should copy the file there. That way if a developer changes the file during development it will be compiled into the resulting application correctly. When I looked at this particular file I discovered that property was already set to Copy if newer. For experimentation I tried setting the property to Copy always and rebuilding but Visual Studio never actually output the file. Forceful MeasuresTaking matters into my own hands I copied the file there myself to see if it had any effect. Building now produced a different message: 1Project &apos;In-house.Framework&apos; is not up to date. Input file &apos;C:\\dev\\SolutionFolder\\ProjectFolder\\Source\\In-house.Framework\\In-house.Framework.csproj&apos; is modified after output file &apos;&apos;. This is an interesting message, and I wasn’t entirely sure what it meant as it didn’t match the change I had just made. It seems as though somewhere in the complexity of the generated build process, MSBuild determined the project file was changed so it forced a project rebuild. This rebuild was what I expected so I thought I was making progress. Once that build had finished I rebuilt without changing anything and was met with the following message: 1Project &apos;In-house.Framework&apos; is not up to date. Project item &apos;C:\\dev\\SolutionFolder\\ProjectFolder\\Source\\In-house.Framework\\Themes\\Generic.xaml&apos; has &apos;Copy to Output Directory&apos; attribute set to &apos;Copy always&apos;. It appears even though Visual Studio doesn’t actually copy the xaml file, it still checks the Copy to Output Directory property value to see if it needs to force a project rebuild, and does so when the value indicates it should. Bad BehaviourIt appears that for xaml files at least, the Copy to Output Directory property is no longer useful. In conjunction with the messages from the MSBuild output, this property is now a source of confusion. MSBuild expects a xaml file at build time and the usual means of control to ensure the file is present at compile time simply don’t work. What’s worse is those usual means of control actually force a rebuild, which is the action you’re trying to prevent in the first place. Given the manipulation of the Copy to Output Directory property is a common practice by developers to help Visual Studio build correctly, this is potentially a cause of common productivity loss among all UWP developers. Theory about Root CauseI don’t have the means of digging into Visual Studio’s code or MSBuild to find exactly why this happens. From experimenting with the presence or absence of xaml files in the bin folder, different Copy to Output Directory property values, and many, many rebuilds I have developed a theory about what is going on. In UWP, the xaml files are no longer used in the build process that requires them to be present in the bin folder. At some point in the past, binary representations of the xaml files (the xbf format) began being built and output for use in XAML applications, rather than the plain text xaml files. It is these xbf files that are important to be present in the bin folder at compile time, not xaml files. The MSBuild messages are leading the developer astray. I suspect that when the binary format feature was being implemented by Microsoft, an oversight or deprioritised task (or two) meant the messages from MSBuild weren’t updated, and Visual Studio wasn’t updated to properly support the new feature. The result is a perfect storm causing a bad consequence, and the impact is widespread productivity loss for UWP developers. The Actual FixEmpowered by the knowledge I had accumulated through investigation and the theory about the root cause, we can finally address the rebuild problem. The fix is simply to tell Visual Studio not to copy the xaml files at all (set the Copy to Output Directory property to Do not copy) and allow the xbf feature to do what it’s supposed to do. Once in this configuration everything works as it should; changes to xaml files are correctly detected by Visual Studio (forcing a recomple), xaml files without changes are correctly skipped (no recompilation), and cleaning the solution (via Visual Studio or by removing the bin and obj folders from the file system by some means) and building correctly forces a recompile. Of course, you will need to find all the xaml files in your projects that have unwanted Copy to Output Directory property values, because each will cause unwanted builds. This is easily done by opening each of your UWP projects in a text editor (like VS Code) and searching for (and removing) CopyToOutputDirectory elements on any xaml Page elements. ConclusionSetting the Copy to Output Directory property to anything but a value of Do not copy on xaml files is now considered a bad decision. Doing so will cause unnecessary compilation of your UWP projects, which will hamper your productivity as a UWP developer. I hope the various teams at Microsoft can come together to address both the misleading messages from MSBuild and the Visual Studio behaviour around the Copy to Output Directory property on xaml files at build time. An improvement could be to provide a compiler warning when the value is not set to Do not copy; this could improve developer awareness that setting these properties now has unintended and (likely) harmful consequences. In any case, fixing both of these issues will squash yet another cause of poor productivity for UWP developers, and that would be a good thing.","categories":[{"name":"developer","slug":"developer","permalink":"http://www.redperegrine.net/categories/developer/"},{"name":"flow","slug":"developer/flow","permalink":"http://www.redperegrine.net/categories/developer/flow/"},{"name":"productivity","slug":"developer/productivity","permalink":"http://www.redperegrine.net/categories/developer/productivity/"}],"tags":[{"name":"Visual Studio","slug":"Visual-Studio","permalink":"http://www.redperegrine.net/tags/Visual-Studio/"},{"name":"MSBuild","slug":"MSBuild","permalink":"http://www.redperegrine.net/tags/MSBuild/"},{"name":"UWP","slug":"UWP","permalink":"http://www.redperegrine.net/tags/UWP/"}]},{"title":"Waiter...my Menu is all GUI!","slug":"menu-all-gui","date":"2018-09-26T08:26:36.000Z","updated":"2019-05-01T09:07:05.583Z","comments":true,"path":"2018/09/26/menu-all-gui/","link":"","permalink":"http://www.redperegrine.net/2018/09/26/menu-all-gui/","excerpt":"I built a front end UI for my capability tests.","text":"I built a front end UI for my capability tests. BackgroundAs I ported my accelerometer test (the subject of my last post), I realised creating an app for each test on my Android phone was going to be problematic. When I originally built these tests as UWP apps for Windows Phone in Visual Studio, deployment was easy. It was cheaper in time and effort to just deploy a new app each time rather than building a UI and hosting them in a single app. However deploying to UWP and Android in Godot has different overheads. It takes significantly more effort to configure the project, obtain signing certificates, and do the app signing. Having gone through the pain once I knew I didn’t want to spend time jumping through those hoops every time I created a new test app. It was time to build myself a small UI to choose which test to run within the bounds of a single app, and a simple menu is perfect for this purpose. Designing the MenuBecause the next capability test I will convert requires knowledge of Godot UI control nodes, exploring them now on something simple is a logical first step. A menu that fulfills my current need will show an app title, and a button for each test to choose from. Each button will show the title of the capability test it represents and an image representing what the test looks like when it’s running. I decided to make the menu content dynamic so that updating it with each new test I build will be trivial. A data driven menu is the way to go in this case, so I created an array of dictionary objects with properties of name, thumbnail (image filepath) and path (scene filepath). This is the minimum data each button needs to render and run a test when pressed. 123456789101112var Apps = [ &#123; name = \"Touch Manipulation\", thumbnail = \"res://game/menu/thumbnails/ManipulationTest.png\", path = \"res://touchInput/touchInput.tscn\", &#125;, &#123; name = \"Accelerometer\", thumbnail = \"res://game/menu/thumbnails/AccelerometerTest.png\", path = \"res://sensorInput/sensorInput.tscn\", &#125;,] The data to define the app buttons on the menu Scene ControlOn each test I’ve built in Godot up to this point, I’ve configured the project’s main scene (the one that runs when you hit F5) to be the test I was actively working on. Now it was time to implement things properly; constructing a game root node with dynamic loading and unloading of child nodes, thereby changing the scene that is being displayed. When the app starts the game’s root node is pre-loaded with the Menu scene, and when a test is chosen in the menu the game will remove the Menu scene and add the scene of the chosen test. I created a separate game folder so that the implementation of the game logic (loading and unloading children etc) wouldn’t bleed into the implementation of each test. For the time being I kept my tests in their own folders directly under the res:// root folder, though it’s likely I’ll reorganise this to avoid clutter as I add more tests. Here’s how this looks on disk: The Menu SceneAs stated earlier the Menu will show the app title and a button for each test. A left-aligned title with a nice big font will be at the top. In the remaining space underneath I will lay buttons out horizontally across the screen, wrapping to the next line when there are too many to fit. Some space around these pieces will let the UI breathe. To achieve this I used a MarginContainer with some healthy margins to provide the breathing room. To that node I added a VBoxContainer containing a Label node for the app title and a GridContainer for the buttons. I put the GridContainer inside its own MarginContainer so I can specify additional space between the buttons and app title. The SceneButton SceneI designed each button to have a centred image at the top, the test name (title) centred horizontally at the bottom, and a border around them both for aesthetics. I used a Panel to give the illusion of a border, though it’s really just a big coloured box taking up the whole background. Inside that I created a Button node inside a MarginContainer for creating this border illusion. The Button node contains a TextureRect and Label node inside another VBoxContainer to achieve a vertical layout, and each is wrapped in its own MarginContainer to get the spacing just right. I called this scene a SceneButton because it’s a generic button that defines which test scene the game will load when clicked. NoteIn hindsight it may have been better to put the Panel and MarginContainer inside the Button node, which would have made the entire button clickable. For the purpose of this post let’s call this a “feature” and move on. Controlling Scene Loading with SignalsThe SceneButton fire’s a pressed signal that is received by the game node when clicked, and it passes the filepath of the scene to load as a parameter. The SceneButton script connects to its internal Button node to detect the actual button press, and simply emits the pressed signal with the filepath that is configured when the button instance is created. 12345678910111213extends Controlexport(String, FILE, '*.gd') var ScenePath = '&lt;some default file path&gt;'onready var buttonNode = $Panel/MarginContainer/Buttonsignal pressed(pathToScene)func _ready(): buttonNode.connect(\"pressed\", self, \"OnButtonPressed\")func OnButtonPressed(): emit_signal(\"pressed\", ScenePath) Signals in the SceneButton (code edited for brevity) Configuring the SceneButtons at Run TimeWhen the app loads and the game scene is ready, its script loops through the Apps array shown earlier and creates the instances of SceneButton. Each instance is populated with the properties of the scene it represents, and its pressed event is connected to an OnButtonPressed handler in the game. 12345678910extends Nodeonready var SceneButtonGrid = $menuContainer/VBoxContainer/MarginContainer/SceneButtonGridfunc _ready(): for app in Apps: var sceneButton = load(\"res://game/menu/SceneButton.tscn\").instance() sceneButton.Initialise(app.name, app.thumbnail, app.path) sceneButton.connect(\"pressed\", self, \"OnButtonPressed\") SceneButtonGrid.add_child(sceneButton) Instancing the SceneButtons (code edited for brevity) Finally, the OnButtonPressed handler creates an instance of the scene that was passed from the clicked SceneButton, adds the instance to the game’s root node, and removes the Menu scene node. 123456onready var MenuContainer = $menuContainerfunc OnButtonPressed(scenePath): var appInstance = load(scenePath).instance() add_child(appInstance) remove_child(MenuContainer) Handling a SceneButton press (code edited for brevity) The Completed MenuAfter a bit of styling I’m happy with the result. Now I have a basic framework to showcase all the tests in one place that’s easy to extend as new tests are built. The source code is up on a Gist. Bon appétit!","categories":[{"name":"gamedev","slug":"gamedev","permalink":"http://www.redperegrine.net/categories/gamedev/"},{"name":"indiedev","slug":"gamedev/indiedev","permalink":"http://www.redperegrine.net/categories/gamedev/indiedev/"},{"name":"godot","slug":"godot","permalink":"http://www.redperegrine.net/categories/godot/"},{"name":"gdscript","slug":"godot/gdscript","permalink":"http://www.redperegrine.net/categories/godot/gdscript/"},{"name":"zodproj","slug":"zodproj","permalink":"http://www.redperegrine.net/categories/zodproj/"},{"name":"game","slug":"zodproj/game","permalink":"http://www.redperegrine.net/categories/zodproj/game/"}],"tags":[{"name":"GUI","slug":"GUI","permalink":"http://www.redperegrine.net/tags/GUI/"},{"name":"Menu","slug":"Menu","permalink":"http://www.redperegrine.net/tags/Menu/"},{"name":"Godot","slug":"Godot","permalink":"http://www.redperegrine.net/tags/Godot/"},{"name":"GDScript","slug":"GDScript","permalink":"http://www.redperegrine.net/tags/GDScript/"}]},{"title":"Instrumenting the Accelerometer","slug":"instrumenting-the-accelerometer","date":"2018-09-09T10:08:52.000Z","updated":"2019-05-01T09:06:59.665Z","comments":true,"path":"2018/09/09/instrumenting-the-accelerometer/","link":"","permalink":"http://www.redperegrine.net/2018/09/09/instrumenting-the-accelerometer/","excerpt":"Converting my accelerometer capability test from UWP to Godot 3.","text":"Converting my accelerometer capability test from UWP to Godot 3. BackgroundHaving successfully ported my touch manipulation capability test from UWP to Godot 3 (the subject of my last post) it was time to prove the capability of another sensor using Godot; the accelerometer. I haven’t posted about this test before (even on my you-tube channel), so let me set the scene for you. The game I’m developing will be controlled by tilting a smartphone or tablet in the real world. Even in their cheapest form, these devices tend to have an accelerometer sensor. Some expensive ones have additional sensors such as gyroscopes and magnetometers which can also be used to determine/enhance how the device is tilted in space. Though prior research and testing I discovered I can get the degree of control I need for the game I’m building using the accelerometer alone. Initially this was revealed with a capability test (the remake of which is the subject of this post), but also later when I developed playable parts of the game on the previous game engine I was developing myself (see my first post). Accelerometer Crash CourseImagine the screen you’re reading this on is a device with an accelerometer. The accelerometer in this device defines it’s movement through real world space using a 3D cartesian coordinate system. It defines an x, y, and z axis through the screen as follows: the x axis passes across the face of the screen from left to right the y axis passes across the face of the screen from top to bottom the z axis passes through the screen from back (behind) to front NoteIf you’re wondering, the origin of the axes (the point where all three axes intersect) is the top-left hand corner of the screen. However that doesn’t matter when we are talking about readings from the accelerometer. The accelerometer measures the acceleration of the device in real world space on these three axes at the time a reading is taken. Readings from the accelerometer are split into x, y, and z values. The accelerometer sensor is constantly measuring so it can provide values any time you take a reading. The Gravity of the SituationThe key thing to understand is that gravity is always affecting these readings. Unless you’re lucky enough to be holding this device in outer-space or on another world, the force of Earth’s gravity is constantly accelerating the device towards the centre of the Earth. If the device is placed on a stationary table and you read the accelerometer you’ll find a force of 9.8 meters per second towards the centre of the Earth being reflected in the results. That’s the amount of force gravity is exerting on the device and the direction in which it is being exerted. This fact can be used to determine the orientation of the device in the real world, and therefore how much the device is tilting. This amount of tilt is what is used to control the game. Visualising the ReadingFor the purpose of this capability test, the screen is a 2D surface on which I want to show the 3D reading from the accelerometer sensor. I chose to represent the x and y component of each reading as a line from the centre of the screen pointing in the same x and y direction, with a length reflecting the strength of the reading in that direction. I also chose to draw a circle around the screen centre to indicate where a force of 9.8 metres per second is, so that if the screen was perfectly stationary and upright (where z == 0) the line would terminate at the circle. This lets me demonstrate rotation around the device’s z axis. For showing the z value of the reading I needed to be creative. I chose to represent the z component by changing the fill colour of the circle. When the z reading is zero, the circle is transparent. When the screen is facing the centre of the Earth, the circle is solid green. When the screen is facing away from the centre of the Earth, the circle is solid red. As the screen tilts towards and away from the centre of the Earth, the colour gradually changes between these three colour values. The end result is that it becomes easy to see which direction the centre of the Earth is on the device as you tilt it through space. It’s quite difficult to explain in words, so let’s jump ahead and see a video of this in action after this capability test has been implemented. Accelerometer capability test in Godot on my Android phone Reading the Accelerometer in GodotIn UWP the accelerometer sensor is exposed in the Windows.Devices.Sensors. You define the interval at which readings will be taken, and an event handler that will receive each readings. In the previous implementation of this capability test I wrapped this sensor object in a service that stored the values as readings came in, and the application simply read from this service when it is was ready to take a reading. In Godot 3, the accelerometer sensor is exposed as a function get_accelerometer() on the Input singleton, which returns a Vector3 containing the x, y, and z values. At the time I was coding, the Godot help system described the functionality of this method as: If the device has an accelerometer, this will return the movement. I knew my Surface Pro (where I do all my coding) had an accelerometer from when I wrote my UWP version of the capability test. When I read the sensor in Godot however, I was only getting zeros. Confused and unable to figure it out myself, I turned to Godot Discord for help. Some friends there did some digging and found the get_accelerometer() method only returns values when you export your code and run it on a device where an implementation has been written. Though it’s fortunate that both UWP and Android (my primary targets) have this implementation, being forced to export the code to test it every time is far from ideal. Unless I came up with a plan, I wouldn’t have a tight development loop and progress on my entire game would be painstakingly slow. Making it betterThe documentation totally misled me here but there’s a couple of things I can do to make it better. The first is to submit a pull request on the documentation to write better text and prevent confusion. The second is to request for the Godot development team (or community contributor) to implement accelerometer support within the editor (if the device supports it). I plan to take an action on these. Tightening the Development LoopI wanted to simulate moving the device in real space while in the editor, but I knew get_accelerometer() would only return zeroes when running there. However I could make an accelerometer sensor node (a facade) that exposed readings from get_accelerometer() when it was returning values, and create touch controls to manually update the values when get_accelerometer() wasn’t returning values. Then if I only consume the facade my application would work in both scenarios. I designed a touchscreen vertical slider for the left edge of the screen whose value controlled the x and y readings on the sensor facade. Dragging up and down the slider would change its value between 0 and 360, which I would transform into a 2D direction in x and y using sine and cosine trigonometric functions. I allowed the slider to cycle through this range several times down the screen, and put a marker at every zero point. Similarly I designed a touchscreen horizontal slider for the bottom edge of the screen to change it’s value between -180 and 180 and use it to control the z reading on the sensor facade. Using what I had learned about touch input from my manipulations test to quickly knocked out TouchSliderVertical and TouchSliderHorizontal nodes. I created an AccelerometerSensor node (the facade) that would read from get_accelerometer() a few times when it started up, and if it didn’t get a non-zero reading it would determine that the accelerometer sensor wasn’t present. It would set a boolean flag to indicate if the sensor was available, and not read the sensor further if it determined it wasn’t there. This flag was also used to disable the touch sliders if the sensor was available (so the sliders wouldn’t appear if they weren’t required). Putting it all TogetherNow it was time to put all this into a scene. I built a SensorDisplay node to draw the line and the circle, using the readings from the AccelerometerSensor facade (node). A script on the root node connected up all the necessary signals to marshall readings from the touch sliders to the facade, and to disable them if the sensor was present. I even threw in a DebugLabel to show the state of the AccelerometerSensor. Here’s a video of it all hooked up and running from the Godot editor. You can see the touch sliders in action, how they modify the readings of the accelerometer facade, and thus drive the display. Accelerometer capability test in Godot running from the Editor Smoothing Sensor Readings with FiltersI know from experience that raw readings from an accelerometer sensor are noisy and not suitable for using as input in most cases. The way around this is to filter the readings to smooth out the values. There are many strategies that can be employed to smooth the data, and choosing the one that works for you takes some experimentation. From previous efforts I’ve found a simple low-pass filter is adequate for my needs. Such a filter uses both the previous value and the current reading, performs some simple mathematics and creates a new value. This is remarkably easy to do, and given a good dampening coefficient (again found through trial and error) the readings become smoother and more useful. 12345678910var x = 0.0var y = 0.0var z = 0.0var coefficient = 0.35func _process(delta): var reading = Input.get_accelerometer() x = x + coefficient * (reading.x - x) y = y + coefficient * (reading.y - y) z = z + coefficient * (reading.z - z) A simple low-pass filter to smooth readings from the accelerometer GDScript vs C#It’s worth comparing the implementation of this filter with the implementation from my previous capability test in C# on UWP. In the previous test I separated the accelerometer facade and the smoothing function, then replicated values in a view model and synchronised them with the sensors own ReadingChanged event and the INotifyPropertyChanged event. The implementation was spread across multiple files, and while technically and architecturally acceptable, the simplicity of the implementation in GDScript gives me comfort and confidence in moving ahead on the Godot platform. Exporting to Target PlatformsYou’ve already seen the end result on Android in the video earlier in this post. While exporting to my phone (another device) may feel more complex, it’s actually the easier export path. Once setup, the Android export is as simple as clicking a button in Godot and it’s all done for you. Exporting to UWP is more difficult as Godot doesn’t handle bumping up the version number or completely signing the exported file out of the box. It does handle signing with a developer key automatically on export which is something, however to run the result on Windows you also need to sign the resulting file with a certificate to create a trusted executable. I currently do the non-Godot actions on the command line, and I plan to take some time to automate this with script in the future. Despite the clunky export process, once you have the executable it works just as well as the Android version. Accelerometer capability test in Godot running on my Surface Pro ConclusionAlthough it wasn’t as issue-free a journey as I was expecting the result is pretty satisfying. I was again impressed with the ease at which the Godot solution came together, and hopefully making the accelerometer work when running from the editor can be added to the platform in the future to make the developer experience even better. Coding this capability test in Godot was all too easy and the challenges I encountered were relatively simple to resolve. I was helped greatly with my experience having built this test before, however it’s encouraging to know that if you know what you want to build then building it in Godot is a pleasurable and productive experience.","categories":[{"name":"gamedev","slug":"gamedev","permalink":"http://www.redperegrine.net/categories/gamedev/"},{"name":"indiedev","slug":"gamedev/indiedev","permalink":"http://www.redperegrine.net/categories/gamedev/indiedev/"},{"name":"godot","slug":"godot","permalink":"http://www.redperegrine.net/categories/godot/"},{"name":"gdscript","slug":"godot/gdscript","permalink":"http://www.redperegrine.net/categories/godot/gdscript/"},{"name":"zodproj","slug":"zodproj","permalink":"http://www.redperegrine.net/categories/zodproj/"},{"name":"game","slug":"zodproj/game","permalink":"http://www.redperegrine.net/categories/zodproj/game/"}],"tags":[{"name":"Godot","slug":"Godot","permalink":"http://www.redperegrine.net/tags/Godot/"},{"name":"GDScript","slug":"GDScript","permalink":"http://www.redperegrine.net/tags/GDScript/"},{"name":"Sensor","slug":"Sensor","permalink":"http://www.redperegrine.net/tags/Sensor/"}]},{"title":"Saying G'day to Godot","slug":"say-gday-to-godot","date":"2018-08-21T13:09:17.000Z","updated":"2019-05-01T09:05:43.481Z","comments":true,"path":"2018/08/21/say-gday-to-godot/","link":"","permalink":"http://www.redperegrine.net/2018/08/21/say-gday-to-godot/","excerpt":"I’ve taken my first steps to developing a game on the Godot 3 game engine.","text":"I’ve taken my first steps to developing a game on the Godot 3 game engine. BackgroundFollowing a thorough selection process outlined in my last post I selected Godot 3 as the game engine I would build a game with. The game is a top down 2D shooter, and much of the design had been created previously as I was developing it on an engine I was building myself at the same time. Things didn’t work out with the OS I was targeting, and I’m now planning to build it with Godot 3 for mobile and tablet devices on the Android and (probably) iOS platforms. Check out my previous posts which cover the journey so far in more detail. infoHow does one pronounce “Godot”? I’ve seen and heard a lot of discussion this topic. The game engine is named after the play “Waiting for Godot”, whose admirers also have strong sentiment about correct pronunciation of the word. I couldn’t find any conclusive answers, so I’m going with the first pronunciation I heard; the “g” sound from the word “green” followed by a “doh” sound as in the “dough”. I very, very slightly pronounce the first “o” as well but it’s barely noticable. In fact, it sounds almost the same way we Australians pronounce the word “G’day”, hence the name of this blog post. What to Build First?Given I’m effectively back where I was when I started on my own engine, it makes sense to rebuild the same capability tests I had to ensure Godot was able to accommodate the game features I have in mind. As well as helping me to learn Godot, it’s also an opportunity to compare the performance of Godot over my own engine by implementing the same tests. I expect to find Godot performs much faster than my own engine as it’s much closer to the metal than I was working previously, but it will be great to see this in practice. I chose to port my touch manipulation capability test first. Touch input is the area I have the most concern with in Godot, and my test should be relatively simple to port. My game uses touch and gestures for controls, and the touch manipulation capability test allows me to explore the touch features in Godot. The test is simple; three coloured boxes that can me moved by a drag gesture, scaled by pinch and zoom, and rotated with a twist of two or more touch points. The boxes are selectable, so once selected you don’t have to be touching the object to continue manipulating it. Here’s a video of the completed test on my former engine (running on Windows Phone) to show how this works: Touch manipulation capability test on my former engine Coding with GodotWith Godot there are several language choices, including C# (which I have most of my experience in). However I chose to start with Godot’s own scripting language; GDScript. This language was developed specifically for Godot by their core development team and I felt it would be much easier for Godot to convert my intentions into native code on my choice of target platforms if I used it. Besides, new Godot features would probably appear in GDScript first and I’d prefer they be available for me if I need them. There was also the opportunity to use external editors for coding. My favourite code editor is VS Code and it already had multiple extensions for working with GDScript. After running with both the Godot editor and VS Code for a while, I found the convenience of working inside the Godot editor far outweighed the features the editor lacks (touch scrolling the code window and multi-line editing for example) and I went all in with the built in editor. When creating objects in Godot you define a “scene” which is a composition of a hierarchy of “nodes”, each with it’s own purpose. It took me a while to find the right nodes to use for this test, and after a while I realised I was implementing my objects at the wrong level. I was misled by the word “scene” and thought it was synonymous with “view”, and while you probably can work this way it’s not how Godot is designed to work. A scene is more synonymous with “class” or “entity”, and a view is just a scene that composes multiple other scenes together. Nodes are like characteristics or behaviours of the scene and it’s the combination of composing nodes into a scene that defines the object. Nodes can contain any number of other nodes, and nodes can be instances of scenes. This allows the kind of encapsulation and inheritance heirarchies you would expect from an object oriented language, so all the OO coding patterns and techniques still apply. It was relatively easy to become familiar with the way scenes and nodes work together to form larger pieces, and I quickly became confident with dealing with problems as they arose. Of course, I still needed to familiarise myself with what all the built in nodes were for, so I continued to watch youTube tutorials to see how other people solved the problems I would be coming across as I build out my game. Input with GodotGodot has a comprehensive input event system where input events are propagated through all nodes in a scene on every cycle of the game loop. Various events on nodes are fired until the event is marked as handled or passes all the way through, allowing several ways to accommodate different input processing methods. As well as raw input information, a built in input map system allows you define maps from various input devices (keyboards, joysticks, mice, console controllers, etc). Input maps abstract the controller away from the event handlers and simplifies your code. In my capability test, touch input was my focus. While simple touch gestures allow “click” and “double-click” control out of the box, more complex manipulations need to be constructed from raw “screen touch” and “screen drag” events. This was in contrast to where my original test was written, as UWP has a built-in manipulations class that supports all sorts of gestures. While creating custom gesture handling can be frustrating, it can also be beneficial. Even though I lost some time developing the gestures I needed, I know I’m not having to employ a bloated built in node containing gestures I don’t need. Further, as more and more people adopt touch devices and Godot 3, there’s opportunity to share community-built solutions such as this to speed up the development process for everyone. It’s worth mentioning that while I did search for and find some pre-existing touch handling code for Godot, it wasn’t in a format I preferred and I wasn’t sure if it was performant. I decided to use writing my own handler as a step to learning to code in Godot and use existing material for reference to help solve my problem. Manipulations in GodotIn the previous version of my capability test on UWP I found the delta events of manipulations worked very well when consuming the events. Delta translation, rotation, and scale values are easily applied to matrix transforms on objects, so my touchController (as I called it) would definitely expose these events in signals somehow. To get to this point I would need to process the raw InputEventScreenTouch and InputEventScreenDrag events from Godot and apply some logic to convert into my manipulations into signal data. I started with simple touchStarted and touchStopped signals that would fire whenever a finger started touching and stopped touching the screen. This essentially echoed the Godot InputEventScreenTouch event’s pressed property, but allowed me to start creating a touchInput scene with the controller signals connected up to a debug label for testing. Selectable BoxesNext I needed to draw the coloured boxes to be manipulated on the screen. Godot doesn’t have any vector shape nodes that I could find, so I ended up creating a colourBox scene with a custom draw method to draw squares with borders. I draw two squares on top of the other (first with the border colour, then a smaller one with the fill colour) which ensures the border looks crisp and doesn’t antialias/bleed when the box is scaled. I added some variables for the border and fill colour, and for the size of the box and the width of the border. Then I created a generic function to create instances of the 3 boxes in my scene (red, green, and blue). Now I wanted to make the boxes selectable. I was expecting the built-in input system would provide a way to determine the top-most object under a point on the screen but it appeared not to be so. After discussing the issue on the Godot Discord and toying with a few approaches it seemed the best approach in my circumstances was to allow the boxes themselves to set some state if they were touched and have a controller in the parent scene determine which shape should be selected if multiple hits were reported. While this felt a little clunky and over-specified at first, it did lend itself to developing a selectionController that isolated the selection of boxes from the rest of the parent scene to hide most of the clutter. I considered going a step further and creating a behaviour node that would be added to boxes when they are registered with the selectionController to encapsulate the input logic, but I don’t know if I’d ever reuse that code so I’ve left it as is for now. All that remained is for the selectionController to work out which node is selected by looping through the registered boxes, examining whether they were being touched, and assigning to a variable for use in the main scene. Translation ManipulationNow that I had selectable objects it was time to create the manipulations I needed. I went for the easiest one first; the translation. From my experiment with creating touchStarted and touchStopped signals I knew that each touch point would be assigned it’s own ID (called “index”), and those indexes are created using an increasing integer. When a touch starts I add the index, origin, and position to a dictionary of touch points for tracking. I also record the index of the highest touch point seen, which I use later to form the manipulations loop. During InputEventScreenDrag events from Godot I update the position of the stored touch points in the tracking dictionary. If the event drag is on the point with the highest index I call a manipulation handler, forming the manipulation loop. When touch stops (the InputEventScreenTouch event with event.pressed equal to false), I remove the point from the tracking dictionary (and update the highest index if required). 123456789101112131415161718192021222324252627282930313233func _input(event): if event is InputEventScreenTouch: if event.pressed: # add point to register var tp = &#123; \"index\": event.index, \"origin\": event.position, \"position\": event.position &#125; touchPoints[event.index] = tp touchPointCount = touchPoints.size() # remember highest index for synchronising manipulation signals maxIndex = event.index # signals emit_signal(\"touchStarted\") else: # remove points lastTouchPoints.erase(event.index) touchPoints.erase(event.index) # update maxIndex if necessary touchPointCount = touchPoints.size() if maxIndex == event.index: if touchPointCount != 0: maxIndex = touchPoints.keys()[touchPointCount - 1] else: maxIndex = -1 # signals emit_signal(\"touchStopped\") elif event is InputEventScreenDrag: # update position of this touch point var tp = touchPoints[event.index] tp.position = event.position # Start manipulation loop if all points have been synchronised if event.index == maxIndex: handleManipulation() All that remained was to calculate the delta translation (vector) using the change in position of one or many touch points. For each touch point in the tracking dictionary, the vector from its current position to its position on the previous pass through the manipulation loop are added together. The result is divided by the number of touch points to calculate the average value. This is the translation delta. 1234567891011121314151617func handleManipulation() : # Calculate translation delta var deltaPosition = Vector2(0, 0) if lastTouchPoints.size() != 0: var lastManipulationCentre = Vector2(0, 0) # the last centre of all touch points var thisManipulationCentre = Vector2(0, 0) # the new centre of all touch points var tpCount = 0 for tpKey in touchPoints: if lastTouchPoints.has(tpKey): tpCount += 1 lastManipulationCentre += lastTouchPoints[tpKey].position thisManipulationCentre += touchPoints[tpKey].position # calculate the last and current manipulation point lastManipulationCentre /= tpCount thisManipulationCentre /= tpCount # calculate delta position deltaPosition = thisManipulationCentre - lastManipulationCentre Once calculated I simply emit a manipulationChanged signal from the controller containing a delta with a translation property containing this translation delta value. In the parent scene I consume this signal by simply adding the delta.translation to the selected node’s position and the “drag” manipulation is complete. 1234567# continuation of `func handleManipulation()`# signalemit_signal(\"manipulationChanged\", &#123; \"delta\": &#123; \"position\": deltaPosition &#125; &#125;) Rotation ManipulationNext I tackled rotation manipulation. The logic for this is different because to create rotation you need (at least) two touch points, and use the angle between them to calculate the delta. If there are more than two touch points, the angle between each neighbouring pair of touch points is added together and averaged. I use another tracking dictionary, keyed by the indexes of the point pair, to compare the change in angle between subsequent passes of the manipulation loop. 123456789101112131415161718192021222324252627282930313233# inside `func handleManipulation()`# calculate angles between touch point pairs (if required)var deltaAngle = 0var touchPointCount = touchPoints.size()touchPairs.clear()if touchPointCount &gt; 1: var angle var thisTotalAngle = 0 var lastTotalAngle = 0 var pairCount = 0 var pairKey var lastPair var thisPoint var nextPoint = touchPoints.values()[0] for i in range(1, touchPointCount): thisPoint = nextPoint nextPoint = touchPoints.values()[i] pairKey = Vector2(thisPoint.index, nextPoint.index) # calculate touch pair data angle = fposmod(baseVector.angle_to(nextPoint.position - thisPoint.position), 2 * PI) touchPairs[pairKey] = &#123; angle = angle &#125; # check if pair is relevant (was present in last pass) if lastTouchPairs.has(pairKey): lastPair = lastTouchPairs[pairKey] pairCount += 1 # get angle details for calculating delta angle thisTotalAngle += angle lastTotalAngle += lastPair.angle # calculate delta angle if pairCount != 0: deltaAngle = (thisTotalAngle - lastTotalAngle) / pairCount This angle delta is inserted into the delta object in the manipulationChanged signal, and consumed by adding the value to the selected node’s rotation property. This completes the implementation of this manipulation. 12345678# inside `func handleManipulation()`# signalemit_signal(\"manipulationChanged\", &#123; \"delta\": &#123; \"position\": deltaPosition, \"angle\": deltaAngle &#125; &#125;) Coexisting ManipulationsNote how the logic to calculate the translation and rotation work independently on the same group of touch points. This means you can put all five digits of your hand on the screen (for example), and both drag and rotate at the same time. This produces the effect you would intuitively expect and feels very natural. Scale ManipulationThe final manipulation is often called “pinch and zoom” and in my sample project it is used to scale the size of a box up and down. The logic is a lot like the logic for rotation and shares a lot of the code; it requires (at least) two touch points, and the change in distance between each neighbouring pair is averaged to produce the scale delta. The same tracking dictionary is used to track this distance for each point pair between passes of the manipulation loop. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# inside `func handleManipulation()`; merging scale with angle calculation# calculate distances and angles between touch point pairs (if required)var deltaAngle = 0var deltaScale = 0var touchPointCount = touchPoints.size()touchPairs.clear()if touchPointCount &gt; 1: var angle var thisTotalAngle = 0 var lastTotalAngle = 0 var pairCount = 0 var distance var thisTotalDistance = 0 var lastTotalDistance = 0 var pairKey var lastPair var thisPoint var nextPoint = touchPoints.values()[0] for i in range(1, touchPointCount): thisPoint = nextPoint nextPoint = touchPoints.values()[i] pairKey = Vector2(thisPoint.index, nextPoint.index) # calculate touch pair data angle = fposmod(baseVector.angle_to(nextPoint.position - thisPoint.position), 2 * PI) distance = thisPoint.position.distance_to(nextPoint.position) touchPairs[pairKey] = &#123; angle = angle, distance = distance &#125; # check if pair is relevant (was present in last pass) if lastTouchPairs.has(pairKey): lastPair = lastTouchPairs[pairKey] pairCount += 1 # get angle details for calculating delta angle thisTotalAngle += angle lastTotalAngle += lastPair.angle # add distance details for calculating delta scale thisTotalDistance += distance lastTotalDistance += lastPair.distance # calculate delta angle if pairCount != 0: deltaAngle = (thisTotalAngle - lastTotalAngle) / pairCount # calculate delta scale if lastTotalDistance != 0: deltaScale = (thisTotalDistance - lastTotalDistance) / lastTotalDistance The scale delta value is inserted into the delta object in the manipulationChanged signal. Consuming it is slightly different, as this value is multiplied by the selected node’s scale property to produce the intuitive affect. 1234567# signalemit_signal(\"manipulationChanged\", &#123; \"delta\": &#123; \"position\": deltaPosition, \"scale\": deltaScale, \"angle\": deltaAngle &#125; Coexisting ManipulationsNote again that the way this manipulation works does not interfere with the other two manipulations, and produces an intuitive, natural way to manipulate objects using the same touch points. Manipulations and InertiaIn the original demo I could flick boxes around manipulations whereas in my Godot version I cannot. In UWP, the built in manipulation system had an inertia feature that I chose not to implement in my Godot version. I don’t require this feature for my current game, however if I ever need to add inertia manipulations I think it would be relatively trivial to add the logic to my touchController. Ship it!My touch manipulation capability test was now complete. While things worked great running this test on my Surface, I really wanted to see it on mobile (at least on Android). I wanted to ensure that when Godot translated to a different set of binaries the behaviour of the manipulations wouldn’t change. At the time I was using Godot 3.0 and setting up to deploy to Android was a pretty convoluted and painful. This was mostly due to having to install tooling and configuration outside Godot, as the config inside Godot itself was relatively easy. Since then a lot has happened, with some changes with the way the Google app store treats Godot applications, and decisions about how Godot supports Android exports, and I’m happy to say there appears to be plans to simplify things a lot for Godot 3.1 (or at least in a near-future version). Once Godot (and my development machine, and my Android phone) were correctly configured, exporting to Android wsa a breeze. When I connect my phone to my Surface, an option appears in Godot to deploy to Android at the press of a button. A few brief moments later and my capability test was running on my Android phone and working in every way it did on my Surface. You beauty! Final thoughtsWhile it was initially disappointing that I had to build my own manipulation system in Godot, I’m satisfied with the result. The performance of this capability test, at least measured through my own observation, appears on par or better than the previous version. I’ve deployed a Godot app to an Android device, and everything works the way it should, which was a relief. I’m happy that things are progressing and I can move on to the next task. Here’s a video showing the new capability test running on Godot. Touch manipulation capability test on Godot","categories":[{"name":"gamedev","slug":"gamedev","permalink":"http://www.redperegrine.net/categories/gamedev/"},{"name":"indiedev","slug":"gamedev/indiedev","permalink":"http://www.redperegrine.net/categories/gamedev/indiedev/"},{"name":"godot","slug":"godot","permalink":"http://www.redperegrine.net/categories/godot/"},{"name":"gdscript","slug":"godot/gdscript","permalink":"http://www.redperegrine.net/categories/godot/gdscript/"},{"name":"zodproj","slug":"zodproj","permalink":"http://www.redperegrine.net/categories/zodproj/"},{"name":"game","slug":"zodproj/game","permalink":"http://www.redperegrine.net/categories/zodproj/game/"}],"tags":[{"name":"Godot","slug":"Godot","permalink":"http://www.redperegrine.net/tags/Godot/"},{"name":"GDScript","slug":"GDScript","permalink":"http://www.redperegrine.net/tags/GDScript/"},{"name":"Sensor","slug":"Sensor","permalink":"http://www.redperegrine.net/tags/Sensor/"}]},{"title":"Choosing a Game Engine","slug":"choosing-a-new-game-engine","date":"2018-05-08T12:47:17.000Z","updated":"2019-05-01T09:06:10.771Z","comments":true,"path":"2018/05/08/choosing-a-new-game-engine/","link":"","permalink":"http://www.redperegrine.net/2018/05/08/choosing-a-new-game-engine/","excerpt":"I’d decided to use someone else’s engine, but how would I choose which one?","text":"I’d decided to use someone else’s engine, but how would I choose which one? BackgroundMy last post talked about how I stopped developing my own game engine and game targeting Windows mobile and tablets, and was looking for someone else’s engine to build a game with targeting Android and iOS mobiles, and probably tablets. I was leaving 15 months of work behind to move into more populated marketplaces. I needed to quickly decide which engines to investigate, how to choose the best fit for my circumstances, and start learning and developing on the chosen engine. My fixed requirement of developing offline during weekday work commutes still stood and would be a major factor in the both the initial shortlist and final choice. This time around I have a solid portable with plenty of space, so engines with heavy footprints could be on the table. The ShortlistUnity and Unreal Engine were the obvious giants of the industry to evaluate, and I also knew of Game Maker. I’ve seen lovable games successfully created with all three of these engines. Googling around I saw and discarded a plethora of unsuitable engines due to lack or wrong target platforms, lack of developer and/or community support, lack of features and buggy functionality, etc. One engine that continuously appeared in my research and resisted being discarded was Godot, which became a fourth candidate. So I ended up with a list of 4 engines to investigate: Unity Unreal Engine Game Maker 2 Godot 3 The Evaluation ProcessI didn’t have the luxury of working through the list one at a time, building something non-trivial to test the capabilities of each engine. Unfortunately I have very limited time available; certainly not enough to spend hours learning multiple engines (as much as I would love to). Up-front research was required so I read a lot of experiences of other people, crawled through multiple forums to gauge community activity, and slowly figured out what about each engine could be applied to my own circumstances. Knowing my eventual choice could lock me in for a number of lengthy projects, I didn’t want to risk wasting time on an engine that wouldn’t stand the test of time. That didn’t narrow the field at all so I tried to define a requirements list. The current game I plan to build is a top down 2D shooter with quite a few sprites flying around, so the engine needed to accommodate building 2D games and perform well. This knocked Unity and Unreal down a notch because Game Maker and Godot have first class support for 2D while the former two seem to hack 2D from 3D contexts. Another requirement of mine was a minimal learning curve, considering I would be mainly developing offline. I had to relax this requirement a little because when learning new tools you generally lean on online community support and code samples. I settled for looking at the solution architectures that resulted from using different engines and whether they made sense to me. I have seen Unreal development in the hands of an expert first hand in the past and I was left feeling the sub-systems didn’t fit together naturally. I was impressed with what I saw in Godot’s SceneTree and node structure, which felt more synergistic and all-encompassing. This seemed more like where my own engine was evolving to and I just felt more comfortable with it. Given I wouldn’t have to shift my thinking much if I went with Godot, it edged out Game Maker and took a slim lead. At this point Godot was shaping up as a real contender, so I began watching Godot tutorials whenever I could to get a feel for the development process while I continued with my evaluation. I carefully considered how much online support I would need as I developed. To say I’m completely offline while developing is not entirely true; I do whip out my phone and use a data plan to browse for solutions to specific problems when I need to. However phone plans in Australia are notoriously expensive (and mine is no different), so I didn’t want to use my mobile as a hot-spot for downloading large assets from in-built asset stores. This took Unity down another notch, and I began to sour on the idea of going with the bigger engines altogether. I did a broad-sweeping analysis of the community collaboration channels supporting the various engines. Unsurprisingly there was huge amount support for Unity and to some extent Unreal, but I found examples of different issue resolutions to the same problem depending on major and minor version releases. This brittleness sent my spidey-sense tingling, because if I had to research something online I would need to find the right solution fast and not be caught out by version issues. Finally I looked at financial costs. There were a variety of concerns thrown by all engines, from initial outlay costs, to costs for purchasable modules through stores, to costs for building on target platforms, to shares of revenue for successful games that crossed income thresholds. Apart from initial cost outlay, there seemed a number of imaginative ways to extract money from developers for services. I don’t have too much of a problem with that, but for an indie developer like me just starting out I felt any money I made would be paid for in blood and sweat, and I didn’t feel like handing over any cash just yet. Godot won this category by a long shot, being free to use, free to deploy, and with a licencing model that pretty much guaranteed the free model would remain throughout the life of the product. Putting all this together there was a clear winner; Godot was the best match for my circumstances with air visible between it and it’s next competitor (Game Maker). Due DiligenceI wasn’t quite ready to jump on in however. Choosing an engine was one thing, but now I just something to scrutinise to see if it really would be the right fit for me. My biggest concern was the offline aspect of my development process. Godot hosts online documentation as a static website, which allowed me to scrape it using a website copier like WebHTTrack and hosting it rendering it offline locally. The documentation source is also available to allow community submissions and language translations; another positive for community engagement. This would help if when needed to search the “online” docs while offline (search in static websites online is still generally implemented as an online service). Further, Godot also employs a built-in help system Godot with context-sensitivity and search features. This earned it another big tick from me. My next concern was feature support. At the time version 3 was relatively new and is a full rewrite. Where Godot 2 was feature rich and complete enough to be fit for purpose, I had to assure myself that version 3 had ported enough features to allow me to get started. Fortunately it seemed so, and had been around long enough that some fantastic tutorial content from people like Kids Can Code and GDQuest had already been made to teach Godot 3. Community efforts like this showed that version 3 was already in a great state to start my development project. My final concern was to find out about the development of the Godot 3 engine itself. Would the small dedicated development team and enthusiastic community contributors be able to port and create stable features at a reasonable pace, or was there a possibility I could “catch up” and need features from the engine before they had completed? My concern was easily dismissed; the team behind Godot had just secured enough Patreon funding to pay their team full time, and between the time I discovered this fact and the time of writing I’ve been really impressed at the speed which features are emerging, how the operation is being run, and how transparent the team is about progress via social media such as blog posts and Twitter. My ChoiceThere was no doubt at this point; Godot 3 was a clear winner and would be the engine I would build my game with. The only lingering doubts I had was whether I could make the leap between using my own engine (which I knew intimately) and using somebody else’s (which I was pretty clueless on how to work at this point). I wouldn’t find out until I tried it out…it was time to get back to development. If you want to know more about what I’ve been working on, check out my #zodproj posts on Twitter or read through my previous blog posts.","categories":[{"name":"gamedev","slug":"gamedev","permalink":"http://www.redperegrine.net/categories/gamedev/"},{"name":"gameengine","slug":"gamedev/gameengine","permalink":"http://www.redperegrine.net/categories/gamedev/gameengine/"},{"name":"godot","slug":"godot","permalink":"http://www.redperegrine.net/categories/godot/"},{"name":"zodproj","slug":"zodproj","permalink":"http://www.redperegrine.net/categories/zodproj/"},{"name":"gameengine","slug":"zodproj/gameengine","permalink":"http://www.redperegrine.net/categories/zodproj/gameengine/"}],"tags":[{"name":"Godot","slug":"Godot","permalink":"http://www.redperegrine.net/tags/Godot/"},{"name":"Unity","slug":"Unity","permalink":"http://www.redperegrine.net/tags/Unity/"},{"name":"Unreal","slug":"Unreal","permalink":"http://www.redperegrine.net/tags/Unreal/"},{"name":"Game Maker","slug":"Game-Maker","permalink":"http://www.redperegrine.net/tags/Game-Maker/"}]},{"title":"Changes of a Cosmic Scale","slug":"changing-everything","date":"2018-03-29T23:47:31.000Z","updated":"2019-05-01T09:05:24.319Z","comments":true,"path":"2018/03/30/changing-everything/","link":"","permalink":"http://www.redperegrine.net/2018/03/30/changing-everything/","excerpt":"I’ve reached a critical juncture in the development of my game and engine.","text":"I’ve reached a critical juncture in the development of my game and engine. I’ve been developing a game for the past 15 months. It’s been a labour of love, as any indie game developer can attest to. However, recently something happened that has forced me to pivot my roadmap significantly. Before I get to what’s happened I’d better give you some context, because I realise it is sorely lacking at this point. A Brief History of the ProjectOver two years ago I discovered how I could make the time to pursue my dream of developing (and releasing) a game. I’ve wanted to do this my whole life, and after several uncommitted attempts and a gap of at least 20 years since my last try I realised the passion to do this was burning as intensely as ever. What’s more, taking on a side project was going to save my sanity, as my 22+ year career as a programmer wasn’t letting me practice the skills I felt I needed. I love a good synergy, and here I could cover both issues by building a game. I chose to use the Microsoft .NET stack because the bulk of my developer experience is there, and the devices I owned (phone, desktop, laptop) were all in the Windows ecosystem. My laptop was a 128Gb Surface Pro 1 (bought the day they were available) and my phone a Nokia 930 running Windows 10. Both were in fantastic condition (both operationally and aesthetically) despite almost constant usage. However the Surface was so full of development tools and SDKs there was little free space for my project or other tools I would need. I only had very small daily periods to work on the project; my available time was daily train commutes to and from my day job. This started out as a 20 minute commute in the morning and the same in the evening, however along the way I did move house and this became two 30 minute windows that I currently enjoy. In terms of committing time to side projects this didn’t sound enough at first, and the disbelief I could be productive in such small bursts put me off for a long time. Being unable to find any other time I gave it a go, and two years later I’m amazed at how much I’ve achieved. asideI submitted a talk to present this development process at a developer conference last year but it didn’t get up unfortunately. It’s worth sharing the challenges and benefits of this process perhaps one day I’ll at least blog about it. As a consequence of the short periods of time available and being disconnected from the network while commuting, I chose not to start with an existing game engine as I felt it the learning curve require a heavy investment in online tutorials and other online research to be productive. So I decided to build the game engine on my own from scratch as well as the game itself. I know that sounds insane, but I didn’t rush into this decision blindly; I knew it would be super tough (and more than I could imagine), so I did quite a bit of experimentation and exploratory coding before I decided it really was achievable. I knew I would be happy with this decision as it would finally afford me the practical experiences I was craving (writing high performant, memory efficient code, and exploring previously unvisited areas of the .NET Framework), as well as allowing me to dump decades of mental pseudo-code into reality to see if my theories actually worked. Setting My Own ExpectationsGiven it would take a long time to build both an engine and a game from scratch under normal working circumstances, and that I only had 40 minutes a day (20 minute sprints), I had to be realistic about time. Most game developers and studios set themselves deadline/completion dates for their games, but that just wasn’t applicable for what I was doing and how I was working. I chose to not fix a date, but to fix the quality of the game at a high level and it would take “as long as it takes” to build. This meant I could commit to getting the design of the engine right from day one, focusing on performance, no memory leaks, and no blocking garbage collection when playing. The latter was the strongest in my mind, and I did a lot of further research to confirm what I believed was the best practice to avoid garbage collection in .NET (mostly declaring all memory use up front via object pooling). This lead to some satisfying conversations with people who were actively working on the .NET garbage collector at the time, the discovery of a memory profiling tool (BenchmarkDotNet), and a practice of regularly profiling the .NET framework to ensure my choice of code implementations in the engine code were optimal. I even blogged about that in my first blog post. Finally, I knew that if this worked it would be the beginning of a number of games I would produce. I wasn’t expecting to make any money from this first project (being on the Windows marketplace, which is a pretty small market compared to Apple and Google) so I expected to release the result for free, with some clever ideas for monetisation that didn’t change the game dynamics. The value I would get out of this project would be very personal: Practicing and developing the skills I felt were missing in my current skillset (personal skills growth) Keeping sane at work (not trying to force personal development into my day job as it just wasn’t happening) Getting years of game routines out of my head and into reality (overcoming impostor syndrome) Expanding my knowledge of game development terminology and practices (setting myself up for future game projects) Finding other game developers locally and on the web that I could talk to (establishing a new social network) Finding SupportI didn’t take that last point lightly. I knew what I was undertaking would require endurance as progress would be agonisingly slow. I back myself for mental toughness and sheer determination, but it would be foolish to take on such a project without support from others who knew what I was going through. So I reached out to the only game developer I knew (from a meetup he presented at once), who directed me to a local community called Let’s Make Games. I started attending Playup Perth where local developers were provided space playtesting their games for review and feedback. I exchanged Twitter handles with a few local developers and made a few connections. Social media then quickly expanded my network, and even revealed video content such as the excellent vlog Just Make Game by Armitage Games. Starting with MicrostepsMy first development task was to figure out was which rendering technology to use. I wrote several tests to trial Win2D which proved more than adequate. It works great as a performant renderer (siting astride DirectX) and also provides a game loop controller managing timing complexity for fixed timestep loops (and variable if you want it). It cohabits nicely with the Universal Windows Platform (UWP) which was my target language framework. Each new test I created established further confirmation that my stack integrated comfortably, allowing UWP gestures and touch and .NET sensor support (accelerometers and the like). An early test - UWP gestures with Win2D rendering These initial tests took some time but were important. I needed to be confident I wasn’t committing to a path leading to an impassible road block somewhere along the way. They also allowed to solidify my solution architecture while I explored the technology space. Another early test - testing the performance of sprite batches in Win2D As my tests grew in number and I learned more, the design for my game started to form in my mind. Resisting the urge to fully specify the design up front (who knew what I would discover along the way) I fleshed out about 70% of the design without committing to paper (for design agility). I now had my base game design and practical knowledge of the technology choices I could use to build my way there. My direction was established and it was time to start moving. One of the final tests - parallax clouds working across multiple devices with UWP The Zodman Project (#zodproj)After working on the project for several months my enthusiasm hadn’t waned and I had produced a surprising body of work (at least to me). Inspired by other indie devs in my social network, I decided to begin sharing my progress on social networks as well. At the time I didn’t have a blog, so I decided to use Twitter to give tweet-blogs about my work augmented by video. With a need to relate these tweets together I realised I needed a hashtag. I decided to label all my side projects under a single banner; The Zodman Project. Zodman is the nickname/handle that has stuck with me from my gaming days way back in the 1990s, and I’ve used it prolifically as an ID across the web for all this time (using ZodmanPerth when Zodman is already taken). The #zodproj hashtag would be used to group together all my online posts about my side projects and provide some context to individual posts. As a lover of coherent narrative, I felt it was important to start sharing progress from the beginning of the project, so my tweets started with those initial tests and proceeded in linear order. I wanted to show the body of work so far in weekly tweets until I caught up to where I was coding. I found this difficult because I had to find the time to create the video and also maintain my code so that the older tests continued to function while I coded at the bleeding edge of the project. This was particularly challenging as I continuously refactored my engine as I discovered better ways to do things. One other challenge was the size of a tweet which only allowed 140 at the time. While this was a blessing as it brutally focussed the scope of my posts (and let the video do the talking), I started getting that nagging feeling that maybe I should bite the bullet and start blogging as well. A Blog is BornFollowing a lengthy performance investigation with PerformanceDotNet, and having to augment the way it works to concatenate multiple runs into a single report, I finally had something to share that was beyond what Twitter could suitably accommodate. It was time to get my own blog. After scouring the web for ready-made blog services, worrying about loss of IP/data and control over layout and style, I settled on source controlled static site generation and managing deployment and hosting myself. Hexo is a static site generator that suits my commute-working style. Posts are markdown which I edit using VS Code and suits source control. It includes a local node server for testing the site locally prior to deployment. I then deploy to GitHub pages which provides hosting for a single, free, size-limited static website per account. After paying for a DNS entry and routing requests to Github, my blog was online. I had finally created an environment to share ideas in depth the opportunity to start a game blog. However, I struggled to create the time necessary to create blog posts. It takes some time to create posts, especially when you haven’t blogged in a while and you’ve got a lot of ground to cover. I found I wasn’t blogging because of the time required, and all the time I had available went into developing the things I wanted to blog about; Catch 22. Still, at least I was pushing my game and engine forward so I could be happy with that. I resigned myself to remain uncomfortable with falling behind in sharing my journey until I had some time to reflect on resolving the issue. Upgrading my Development EnvironmentEven though things were going pretty well with development I was starting to really feel the lack of disk space was starting to hamper progress. I had been eyeing off the new Surface Pro (2017 edition, 5th generation) with envy, and when my wife’s laptop finally died it was the perfect time to change up and gift her my Surface Pro 1 (a major step up from her awful laptop at least). I went for the basic I5 with 8Gb RAM and 256Gb disk space. I went for extra disk because of my troubles with space in the past. I expected this device would last me for the next 5 years or more, and the knowledge that in that time I would start using pre-built game engines and other tooling that would eat into the free space. The development experience on the new machine wasn’t too different to the 1st generation to be honest, though the additional screen resolution and CPU power made a noticeable difference. The new screen doesn’t handle being in daylight on the train as well though, and I had to purchase a polarised screen protector because when I was wearing my sunglasses I couldn’t read the screen! The screen brightness isn’t as bright either and I still find it a little difficult to read. I must say though that it’s well worth buying the new Surface Pen and nib set. The tilt control allows you to sketch with a feel almost like using a real pencil and I can’t wait to do some art with it when I can find the time. The Game ChangerAnd then it happened…the big whopper; the event that would change everything. Microsoft had released a Windows 10 update that stopped my phone from working properly. First I noticed that my Twitter app stopped scrolling after displaying about 20 posts. This was annoying as every spare moment I had would be spent looking through my feed to stay motivated by the indie dev network. I was missing out on a lot of great content and motivation. Then I noticed my email wasn’t working to well either. I could no longer email research findings to myself for review on a desktop sometime later. The loss of this functionality made things a bit too much to bear. I had encountered similar issues with a prior phone update, but not for such an extended period. The phone partially installs the new update (causing software quirks) but it fails and tries again at the next opportunity (my settings say to try nightly). I waited several weeks before I decided a successful update may not be coming anytime soon. My phone version was out of support with Microsoft so they were under no obligation to correct the issue. I had no idea when the next update would come, or if it would resolve the issue; there were no guarantees the next update would not have similar issues. The platform I was targeting was now unstable and I was forced to reconsider the approach I was taking. Without a stable platform there was no guarantee that the limited customer base that existed would still be there if I got up and running again and managed to finish my game in reasonable time. I had a difficult choice to make. I was weighing up years of lost learning opportunities through developing the engine myself to move forward on an existing game engine that target a set of devices I didn’t own. While it took some soul searching the way forward was inconvenient yet obvious; I had to change platforms sooner than anticipated and target the Apple and/or Android market. The event was literally a game changer. Not a Total LossAs sad as it was, the change did not mean I had wasted a year of development. Let’s look again at the list of things I wanted to achieve: Practicing and developing the skills I felt were missing in my current skillset (personal skills growth) - SuccessI learned a great deal about .NET Garbage Collection, memory management, object pooling, and using arrays in anger. My most recent refactor of the game engine (which was incomplete at the time where “the event” happened), was further proof to myself that I had an excellent handle on solution architecture and that I knew how to make the choices that would benefit working with and extending the engine. Keeping sane at work (not trying to force personal development into my day job as it just wasn’t happening) - SuccessI was a lot happier at work as I was no longer frustrated that opportunities to learn in areas I felt I was lacking never came. I was managing that progress on my own time, and at work I could focus on doing work to the best of my ability and having more fun. Getting years of game routines out of my head and into reality (overcoming impostor syndrome) - SuccessRoutines such as tile maps, sprite batching, user input without compromising architecture, were amazingly cathartic to get out of my head and seeing in real life. The most enjoyable of all though was writing my own collision detection in pure geometry, not only because maths is awesome but because I love explore areas of mathematics I have never seen before. I had expanded my horizons and in doing so blew away any reason to call myself an impostor. Expanding my knowledge of game development terminology and practices (setting myself up for future game projects) - SuccessBecause I worked as close to the metal as my framework choice allowed without fighting the language framework, I was exposed to the gnarly detail of the areas of game development I felt I needed. When I saw people using existing game engines such as Unity and Unreal and had glimpses of how they were structured, it confirmed to me I was doing things right and learning all the right things. Finding other game developers locally and on the web that I could talk to (establishing a new social network) - SuccessI could never have come this far if I were truly alone. While it’s been a disappointing year for socialising with local indie devs, I’ve developed relationships both in my own country and beyond. Though these relationships are new, they give me confidence that I belong among such a group of inspirational and talented people who understand what I’m going through and can support me when I’m feeling down. The Do-OverOverall my effort over the previous year has born substantial fruit and despite my sadness at the passing of an old friend (Windows Phone as a development platform) it can only be called a success. I now have a new direction to move in with purpose, with the benefit of it being a more densely populated market of people to potentially see my wares. Given I no longer need to write a game engine myself, I anticipate my game will evolve more rapidly as I am liberated to focus solely on that. This should go a long way to making me feel a lot closer to the cadence at which other indie devs work, despite still only having two half-hour sprints a day available to devote. I’m hoping more rapid progress will translate into more rapid sharing of screenshots etc, and in doing so any self doubt about being an impostor will be much more infrequent. I’ve been given a second chance to do things right so it’s important I reflect on the journey so far, reinforce what I’ve learned to myself and to consider how to be more effective this time around. The most obvious place to improve is where I have been feeling the most angst; socialising my work. Doing it BetterThrough my effort with social media so far I have discovered which channels are good for different sizes of communication and the frequency that works best on them. Where I have been previously frustrated by my inability to devote time and been blocked because I hadn’t established a channel, I now have a better understanding on how to do it better this time. This means: TwitterThis channel will be used to report up to the minute stuff without context, because the frequent flow of tweets itself creates the context which readers can follow (pun unintended). It should also be used to participate in community groups such as #screenshotsaturday. I will continue to use #zodproj to flag my game tweets and aim to post more often and only with up-to-date information. Game BlogNow that I have created a space to blog I will use it more frequently. I’ve learned that while it is a good channel when you have more words than can be squeezed into a single tweet, it takes far too long to write posts if you leave it too long. Just as frequent releases of software makes deploying releases easier, I’m believe more frequent posts will make blogging easier. Perhaps whenever I pass a major milestone in my development, or perhaps when I’ve passed a few minor ones, I’ll do a quick post so they don’t take too long to write. I’m looking for a sweet spot between creating my game and blogging about it. I hope that now I’ll be using a pre-built, rich featured game engine I can focus on building the game itself, which will create a more satisfying timeline of progress and I won’t feel guilty about taking my limited time away to work on blog posts. Final thoughtsBecause of the limited time I have available it’s taken me two weeks of actual time going by to create this post. In that time I have purchased, received, and set up a new Android phone, been researching game engines for suitability to my development practices, and started learning about one in particular in more detail. I can see I’ve got a long road of discovery ahead before I get back to being as productive as I was, but I believe this effort will rapidly increase the speed at which I deliver and I will be more creative as a result. I look forward to posting more frequent updates in the future.","categories":[{"name":"gamedev","slug":"gamedev","permalink":"http://www.redperegrine.net/categories/gamedev/"},{"name":"indiedev","slug":"gamedev/indiedev","permalink":"http://www.redperegrine.net/categories/gamedev/indiedev/"},{"name":"gameengine","slug":"gamedev/indiedev/gameengine","permalink":"http://www.redperegrine.net/categories/gamedev/indiedev/gameengine/"},{"name":"zodproj","slug":"zodproj","permalink":"http://www.redperegrine.net/categories/zodproj/"},{"name":"gameengine","slug":"zodproj/gameengine","permalink":"http://www.redperegrine.net/categories/zodproj/gameengine/"}],"tags":[{"name":"gameblog","slug":"gameblog","permalink":"http://www.redperegrine.net/tags/gameblog/"}]},{"title":"Measuring C# Performance with BenchmarkDotNet","slug":"measuring-csharp-perf-with-benchmarkdotnet","date":"2017-12-23T09:12:47.000Z","updated":"2019-05-01T09:05:11.594Z","comments":true,"path":"2017/12/23/measuring-csharp-perf-with-benchmarkdotnet/","link":"","permalink":"http://www.redperegrine.net/2017/12/23/measuring-csharp-perf-with-benchmarkdotnet/","excerpt":"I’m measuring optimal C# code implementations for a game engine I’m building.","text":"I’m measuring optimal C# code implementations for a game engine I’m building. BackgroundI recently took on a “little side project” to pursue a lifelong dream: designing, creating (and releasing!) a computer game. Though I’ve had the desire to do this for more than three and a half decades, I never quite got around to making a consistent, concerted effort. It’s not because I’m lazy, I’ve just managed to pack a whole bunch of experiences into my life so far and, until recently, couldn’t find enough time to devote to the cause. By “little side project” I’m being a sarcastic of course. I knew when I started this journey that building a game is no trivial feat, and there would be unknown unknowns that would arise and need to be dealt with along the way. That discovery was part of the exciting thing for me because I love learning new things. However, because I really enjoy a challenge (and from the necessity of my circumstances), I made the decision to write the game engine as well; from scratch. Fortunately I’d pursued life experiences that included all the ingredients I would need to pull off such a feat from both a creative and practical standpoint, including a lengthy career in software engineering and commercial experience in UX design. I’ll explore the circumstances that drove those initial decisions another time. Right now, it’s enough to know that the game engine is written in C# on UWP using Win2D, and targets Windows tablets and phones that have accelerometer sensors and touch screens. The game is a top-down 2D space shoot ‘em up with a retro arcade look. Build A Game Engine in C#…Are You Crazy?When people talk of building game engines, C# and .NET aren’t terribly popular choices. The .NET framework, while a much loved and carefully crafted platform, hasn’t exactly been built for the demands of a high-performing game engine in mind. I don’t think my engine will be too demanding though, so using .NET is a feasible option. Win2D is a powerful ally here, being a finely tuned wrapper over DirectX that is built for performance. Win2D also provides a game-loop that gracefully handles the complexity of loop timing management, so that’s one less thing I needed to worry about. This leaves the game engine “merely” doing some user input handling, physics, collision detections, game logic, and image rendering. What could go wrong right? As long as I build with the Garbage Collector in mind, and execute code in tight enough loops, I would hopefully get a smooth 60 frames per second across my target devices. This is a nice engineering challenge that will keep me happily satisfying my inner geek for some time. Performance Front and CentreI was reasonably sure I could make something decent with my technology choices, and a few test applications later I committed to the task ahead. With a freshly read copy of Bob Nystrom’s amazing eBook Game Programming Patterns up my sleeve, years of mentally constructed game systems and designs that were eager to escape my mind, and the skills I had nurtured over my career, I figured I had a decent shot at a solid result. But confidence alone was never going to be enough. Going into development of the engine I knew I would have to make every nanosecond count. While the architecture was wholly under my control and I trusted my skills, there was one concern that still hung heavy on my mind; would the .NET Framework itself be performant enough? There was only one way to know for sure; I was going to have to write performance tests for the framework itself. And when you want to know the performance of .NET code I know of nothing more suited to the task than BenchmarkDotNet. BenchmarkDotNet and LINQPadI’m a heavy LINQPad user from way back. Among other things, LINQPad enables me to test hypotheses quickly away from the complexity of my larger code bases. Once I’m happy, I move the validated code into the main codebase and do some manual integration tests. This process works really well for me, so when I found myself needing to test different C# implementation patterns in isolation, LINQPad was a natural choice. Fortunately for me my timing was just right; BenchmarkDotNet had just added support for running inside LINQPad, and LINQPad had just added support for hosting BenchmarkDotNet. While the road since has been a little bumpy, the state of both tools was good enough to provide what I needed. Testing Different Iterator Patterns in .NETI really enjoyed writing my own collision detection system; it’s the kind of challenge I relish. My starting point was an excellent tutorial by Nilson Suoto called Collision Detection for Solid Objects, and after a lot of experimentation I had a really tight system. I had a Sort and Sweep service using cheap AABB checks to find collections of objects with potential collisions (the broad phase), which were used to discover the actual collisions using Minkowski Sums and Convex Hulls of object geometries (the narrow phase). We’re not covering the details of the implementation here, but you should know the narrow phase contains expensive CPU operations and I’ve spent an appropriate amount of time optimising the hell out of them. Codewise, the Collision Detection system drives the Sort and Sweep service using an iterator pattern. You probably know this pattern from implementing IEnumerable&lt;T&gt;; GetEnumerator() methods that yield appropriate results. This is how I implemented it at first, and it made for some nice, readable code. However, I had a hunch that this generic interface may not be the most performant way to drive the service, so I devised a plan to test different implementations of the iterator pattern to see if I could find time savings. I also had concerns that the use of generics would add pressure to the .NET Garbage Collector, and as such I was interested in verifying this measuring memory aspects of each implementation as well. Initial BenchmarksSwitching to LINQPad, I wrote up a Worker class to simulate the Collision Detection system doing expensive work by summing the values yielded by a Driver class, which represented the Sort And Sweep service. Main() simply called the benchmark runner to run with the Worker type. I marked up the Worker with a MemoryDiagnoser to report on memory consumption, and because of my cross device intentions I thought it’s prudent to explore 32bit and 64bit generated code. The code looked a little like this: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546[MemoryDiagnoser][RyuJitX64Job, LegacyJitX86Job]public class Worker&#123; [Benchmark] public void NormalEnumerator() &#123; Driver driver = new Driver(); int count = 0; int sum = 0; foreach (int i in driver) &#123; sum += i; count++; &#125; &#125;&#125;class Driver : IEnumerable&lt;int&gt;&#123; const int _size = 10; int[] _array; public Driver() &#123; _array = new int[_size]; for (int i = 0; i &lt; _size; i++) _array[i] = 1; &#125; public IEnumerator&lt;int&gt; GetEnumerator() &#123; for (int i = 0; i &lt; _size; i++) yield return _array[i]; &#125; IEnumerator IEnumerable.GetEnumerator() &#123; return GetEnumerator(); &#125;&#125;void Main()&#123; BenchmarkRunner.Run&lt;Worker&gt;();&#125; As well as the usual output appearing in LINQPad’s results window, running this produced a nice set of reports in various file formats in the subfolder \\BenchmarkDotNet.Artifacts\\results where LINQPad was executing. NoteYou will probably need to run LINQPad as an admin to get it to work. Here’s an extract from a report running this code: From this I was able to reason a few things about a single implementation of an iterator pattern on a small sample size of 10 items. This was a good start and served as proof that the concept of measuring performance in this way worked. Many Rivers to CrossThinking ahead, I knew I had challenges to face. First, an array size of 10 probably wasn’t representative of how big the object arrays would end up in my game. I wasn’t sure how many objects I would need, but I knew performance rarely scales linearly. I wanted to test the same implementations of iterator patterns on array sizes with various orders of magnitude. Unfortunately BenchmarkDotNet didn’t support marking up benchmark methods with injectable parameters (array size in this case), so I had to roll my own solution. Second, while I knew I could have different implementations inside a single Worker, I would need to be careful not to let the sharing of code scope compromise what I was measuring; the implementations could not affect one another. Third, the way I simulated actual work in the implementations had to correctly represent code in my original code base that hadn’t been written yet! Without attention to this detail it would be easy for my abstraction to stray from what would be reality, influencing the implementation and not representing a realistic scenario. Fourth, the implementation code should be reasonably easy to read. I would need to discover where the line was between performance and readability while I thought of innovative implementations. Fifth, I wanted to explore iterators over different kinds of objects such as value types, reference types, and generic types. The result would guide the object structure forming the basis of my collision detection system. Finally, I wanted all these tests to run on a single execution run and roll into a single report table. I figured I would use Excel for final analysis so it would be best if the results were automatically collected together so I didn’t have to do any manual amalgamations every time I completed a test run and wanted explored the results. The Usual Black-Box ChallengesI very quickly discovered that when I performed multiple tests over a single Worker type within the same run, the naming convention BenchmarkDotNet used to create the filenames would result in the overwrite of previous reports. I created a helper class to create backups of report files on disk and track the generated file names. I then added amalgamation of the final report using these backup files using AngleSharp (an open source HTML parser) to rip apart the tables in these files and create my own HTML report. Along the way I also discovered that LINQPad’s Dump() methods weren’t available when BenchmarkDotNet was running, and would cause a terminating exception. This hampered my ability to verify that iterator implementations were working properly (i.e. actually iterating), so I added a “runmode” state to the helper class that allowed me to switch between manual verification of code (where code is executed using LINQPad and not via BenchmarkDotNet) and producing the benchmark reports (where BenchmarkDotNet controlled the execution and not LINQPad). The “runmode” also let me avoid throwing exceptions by isolating calls to Dump() behind conditional checks. Finally, I created a state machine that looped through the various implementations, changing the size of the array each time. The state of the machine was another addition to the helper class. The report backup system hooked into this state to generate unique report names, which were used in turn to create the column values in the amalgamated report. Different Implementations to TestI thought of 4 different iterator implementations to try out: NormalEnumeratorThis was the IEnumerable&lt;T&gt; implementation I already had using GetEnumerator() methods and yield to return results at appropriate points. HandCrankedEnumeratorThis implementation is a POCO with Reset() and MoveNext() methods and an EOF property for controlling the loop. Would removing a broad, generic implementation improve performance and reduce memory usage? HandCrankedWithMoveNextStateThis a variation of the previous implementation that eliminated the EOF and returned feedback from Reset() and MoveNext(). This reduced the number of statements required to drive the iterator which I suspected would translate into better performance. ResultSetFullyCalculatedThis avoided iterating altogether, replacing it with a big synchronous operation calculating all the results in one pass and exposing a Results array. Obviously this would have higher memory requirements, but would it perform better? NoteMy game engine runs on a single thread. Multi-threaded concerns such as the timing of the read and write of values from different threads did not need to be considered. Here’s a gist containing a copy of the final LINQPad code: Amalgamated ReportOnce I was sure all the implementations were working correctly I switched on all the benchmarking options I wanted, plugged in some array sizes, and let it run. On my Surface Pro with an i5 processor this took about 42 minutes, but was worth the wait because the data is rich and dense. Here’s the amalgamated report from one such run. If you’re used to the usual output columns BenchmarkDotNet produces you’ll recognise where I’ve inserted the other relevant data. The Type and Size columns correspond to the type of Worker (IntegerWorker for value type tests, ItemWorker for reference type tests, and GenericWorkder for generic type tests), and the size of the array used to produce the result. The other columns come straight from the BenchmarkDotNet reports. Analysing with ExcelWith all the data is in one place I wanted to use Excel’s analysis tools to help me compare the results and derive conclusions. Copy and paste as text did the trick, though I did have to strip the alphabetical characters from the numeric columns and change their cell format to a number. Once that was done I used a red-green colour scale conditional formatting on the numeric data to create a performance heat map, and used table filters and sorting to do the analysis. Here’s the same amalgamated report formatted this way in Excel: Looking at the Mean column there was an obvious candidate for being too slow; the red cells. Turns out the NormalEnumerator method (the implementation I was already using) was the worst performing, taking almost twice as long as the other methods. I filtered that method out and dug deeper. When I looked at the fasted results in each Size group (those with the greenest Mean values), I could see that the ResultSetFullyCalculated method looked suspiciously slow. I checked each ResultSetFullyCalculated method against the other methods in the same Size group by eye and confirmed it; calculating the results in one hit was slower than flowing back and forth between the Worker and the Driver. asideThis was a pleasant surprise. I had expected a higher memory footprint and a lower execution time. This kind of result is exactly why you need to validate early; it’s much cheaper to build things right the “first time” instead of trying to refactor once you’ve built a whole bunch of stuff on top of a false assumption. I had a real Adam Savage moment with this finding. Science! Let’s filter out the ResultSetFullyCalculated method and keep digging. Now we get down to the pointy end of the analysis. With only two methods remaining to compare against each other, there’s nothing much to do but check each pair individually. The results are really close, and difficult to compare due to the variance in Error and StdDev. However the HandCrankedEnumerator is marginally faster in almost every pair. This was a bit of a surprise given I had assumed less statements in the caller would mean less execution time, but without checking the final generated code you can never be sure how such assumptions pan out. The performance difference isn’t significant enough for me to take my investigation that far, so I’ll happily settle on the variant that’s easier to read, maintain, and is generally faster. How Bad is Your Memory?Did you notice I haven’t talked at all about the memory usage by any of the implementations? Well, throughout my analysis I was giving them the occasional, cursory glance. The fact is, there wasn’t anything significant to worry about. There was only very small Gen 0 in all implementations apart from NormalEnumerator, which was always the highest memory user in each group and always puts the most pressure on the Garbage Collector. The general rule of thumb I’ll be taking forward is that for balancing performance and memory concerns, always go with a POCO. Of course, when it counts I’ll still be testing assumptions of course! SummaryIn the end, because of my findings, I refactored my Sort and Sweep service to be a POCO with Reset() and MoveNext() methods and an EOF property for controlling the loop as per the HandCrankedEnumerator test implementation. It really didn’t take long to convert it over, and I now feel confident and satisfied that through my due diligence I’ve squeezed a little more performance out of a crucial game subsystem. Onward and upward!","categories":[{"name":"gamedev","slug":"gamedev","permalink":"http://www.redperegrine.net/categories/gamedev/"},{"name":"indiedev","slug":"gamedev/indiedev","permalink":"http://www.redperegrine.net/categories/gamedev/indiedev/"},{"name":"gameengine","slug":"gamedev/indiedev/gameengine","permalink":"http://www.redperegrine.net/categories/gamedev/indiedev/gameengine/"},{"name":"tests","slug":"tests","permalink":"http://www.redperegrine.net/categories/tests/"},{"name":"zodproj","slug":"zodproj","permalink":"http://www.redperegrine.net/categories/zodproj/"},{"name":"performance","slug":"tests/performance","permalink":"http://www.redperegrine.net/categories/tests/performance/"},{"name":"gameengine","slug":"zodproj/gameengine","permalink":"http://www.redperegrine.net/categories/zodproj/gameengine/"}],"tags":[{"name":"BenchmarkDotNet","slug":"BenchmarkDotNet","permalink":"http://www.redperegrine.net/tags/BenchmarkDotNet/"},{"name":"LINQPad","slug":"LINQPad","permalink":"http://www.redperegrine.net/tags/LINQPad/"},{"name":"C#","slug":"C","permalink":"http://www.redperegrine.net/tags/C/"},{"name":"Win2d","slug":"Win2d","permalink":"http://www.redperegrine.net/tags/Win2d/"}]}]}